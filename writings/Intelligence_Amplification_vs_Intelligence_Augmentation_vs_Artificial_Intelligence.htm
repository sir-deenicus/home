<meta http-equiv='Content-Type' content='Type=text/html; charset=utf-8'>
                             <script type='text/javascript' async src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML'></script>
                             <title>Intelligence Amplification vs Intelligence Augmentation vs Artificial Intelligence</title>
                             <link rel='stylesheet' type='text/css' href='style.css'>
<h2>Intelligence Amplification vs Intelligence Augmentation vs Artificial Intelligence</h2>

<p>Intelligence Amplification is not the same as Intelligence Augmentation. Why did I select the examples I did in []? Reinforcement learning and evolution? As I stated before, analogies only make sense when a structure preserving mapping is admissible; if not, the sign flips and you're doing negative learning (while appropriate analogies accelerate, no analogies is slower but preferable to negative learning—i.e. unlearning is required).</p>

<p>I picked those two topics because I knew ahead of time they would be extremely similar, thus looking at the mapping would be productive. To contrast augmentation with amplification, amplification is like multiplication, it amplifies what is already there (and so does nothing if you know nothing). Augmentation is additional, although I write about this tool under Int.Aug, it is actually an amplification tool. It takes weak knowledge or associations and amplifies them. Whilst augmentation is apart, amplification is symbiotic. With augmentation the tool acts separately and the human is not part of the process, in fact Augmentation is essentially AI doing all the work but made subservient or rather narrow.</p>

<h3>Artificial intelligence vs Intelligence Amplification</h3>

<p>Consider the building of an analogy <em>F</em>, from <strong>A -> B</strong>. In AI, the agent must have some idea of the structure of both <strong>A</strong> and <strong>B</strong>, after which it can attempt to build <em>F</em>. In the case of amplification, a human needs only weak knowledge that <strong>A</strong> and <strong>B</strong> might be linked after which the program can attempt to build <strong>F</strong>. The process is symbiotic in that neither the human nor the AI is most useful.</p>

<p>Let us take the case of Alpha Go (I'm glad I now have an example to can point to when discussing ideas in AI), it has a very large search space to traverse. The first idea, of generating many scenarios and focusing on branches that resulted in the least regret made headway but was not enough. It was only when a reinforcement learned policy was in use to guide which branches will be most promising ahead of time that search could be pushed to top human levels.</p>

<p>In the case of amplification the machine serves a similar purpose as tree search and the human at the core serves a similar purpose as the policy, guiding towards promising avenues. Of course, the human is vastly more sophisticated as a guide because it can adapt to new information and improve itself on the go. It's symbiotic because the machine generates possibilities and focuses on some areas of promise. This cuts the search space when compared to manually and trying to extract where to focus on. The human analyzes suggestions and in so doing is able to improve its ability to guide the search. Afterwards, it can now bound the search, downweighting and upweighting appropriately and the process continues recursively. In this way, the weak knowledge is amplified much more quickly—the advantage of working memory (reading all the materials and holding it in your head long enough to begin making connections) is reduced and replaced with the simpler requirement of curiosity.</p>

<p>AI needs to be correct but most also avoid getting trapped in valleys (humans often get trapped) by automatically pruning "unlikely" scenarios without consideration.</p>

<p>Balance between being random (creativity) and having direction (dont wander aimlessly—ooh, in writing this I just realized this describes evolution)<br />
Feedback, extension and speed.</p>
